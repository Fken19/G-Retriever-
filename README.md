<<<<<<< HEAD
# graphrag-research

GraphRAGç ”ç©¶ç”¨ï¼šè³ªãƒ»é‡è©•ä¾¡ãƒ¢ãƒ‡ãƒ«é–‹ç™º
ï¼ˆLLMã®æŽ¨è«–ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã€ã‚°ãƒ©ãƒ•ã‚¯ã‚¨ãƒªçµæžœã®è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼‰

---

## ðŸ“‚ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

/src          â†’ Pythonå®Ÿé¨“ç”¨ã‚³ãƒ¼ãƒ‰ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆç¾¤
/data         â†’ å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ï¼ˆ.gitignoreå¯¾è±¡ï¼‰
/notebooks    â†’ JupyterãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
Dockerfile    â†’ Dockerç’°å¢ƒæ§‹ç¯‰ãƒ•ã‚¡ã‚¤ãƒ«
environment.yml â†’ Condaç’°å¢ƒå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«
.gitignore    â†’ Gitç®¡ç†å¤–ãƒ•ã‚¡ã‚¤ãƒ«å®šç¾©
.dockerignore â†’ Dockerãƒ“ãƒ«ãƒ‰å¤–ãƒ•ã‚¡ã‚¤ãƒ«å®šç¾©
README.md     â†’ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜Žãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã“ã®æ–‡æ›¸ï¼‰

---

## âœ… 1. ç ”ç©¶ã®ç›®çš„ãƒ»èª²é¡Œè¨­å®š

### ðŸŽ¯ ç›®çš„

GraphRAGã«ãŠã„ã¦ã€LLMãŒã‚°ãƒ©ãƒ•ã‚¯ã‚¨ãƒªçµæžœï¼ˆã‚µãƒ–ã‚°ãƒ©ãƒ•ï¼‰ã‚’ä½¿ã†ã¹ãã‹ã€ã¾ãŸä½¿ã†ãªã‚‰ã©ã®ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’ä½¿ã†ã¹ãã‹ã€
äº‹å‰ã« **é‡** ã¨ **è³ª** ã‚’äºˆæ¸¬ã—æœ€é©åŒ–ã™ã‚‹ä»•çµ„ã¿ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### ðŸ“Œ èƒŒæ™¯ãƒ»å¿…è¦æ€§

* çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€LLMã®hallucinationï¼ˆå¹»è¦šçš„èª¤å‡ºåŠ›ï¼‰ã‚’æŠ‘ãˆã€æŽ¨è«–ç²¾åº¦ã‚’ä¸Šã’ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
* ã—ã‹ã—ã€ã‚¯ã‚¨ãƒªçµæžœãŒç„¡é–¢ä¿‚ãƒ»å†—é•·ãƒ»çŸ›ç›¾ã‚’å«ã‚€å ´åˆã¯é€†åŠ¹æžœã«ãªã‚‹ã€‚
* ãã®ãŸã‚ã€é‡ã¨è³ªã‚’äº‹å‰ã«è©•ä¾¡ã—ã€é©åˆ‡ãªã‚µãƒ–ã‚°ãƒ©ãƒ•ã®ã¿ã‚’é¸æŠžãƒ»æ´»ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

---

## âœ… 2. è©•ä¾¡æŒ‡æ¨™ã®ç†è§£

### ðŸ“¦ è³ªï¼ˆQuality Estimationï¼‰

ä»¥ä¸‹ã®ä¸‰æœ¬æŸ±ã§è³ªã‚’è©•ä¾¡ã™ã‚‹ï¼š

| æŒ‡æ¨™                  | èª¬æ˜Ž                              |
| ------------------- | ------------------------------- |
| logical consistency | ã‚µãƒ–ã‚°ãƒ©ãƒ•å†…ã®tripleãŒæ„å‘³çš„ãƒ»è«–ç†çš„ã«çŸ›ç›¾ã—ãªã„ã€‚    |
| goal relevance      | ã‚¯ã‚¨ãƒªã®æ„å›³ã«æ²¿ã£ãŸãƒŽãƒ¼ãƒ‰ãƒ»ãƒ‘ã‚¹ãŒé¸ã°ã‚Œã¦ã„ã‚‹ã€‚        |
| hop depth control   | æŽ¨è«–ã®è¤‡é›‘ã•ãƒ»å†—é•·æ€§ã‚’é¿ã‘ã‚‹ãŸã‚ã€2ã€œ4 hopç¨‹åº¦ã«æŠ‘ãˆã‚‹ã€‚ |

### ðŸ“¦ é‡ï¼ˆCardinality Estimationï¼‰

* ã‚¯ã‚¨ãƒªå®Ÿè¡Œæ™‚ã«å¾—ã‚‰ã‚Œã‚‹ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®ä»¶æ•°ï¼ˆnodeæ•°ã€tripleæ•°ï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ã€‚
* ä»¶æ•°ãŒæ¥µç«¯ã«å°‘ãªã„å ´åˆã¯æƒ…å ±ä¸è¶³ã€å¤šã™ãŽã‚‹å ´åˆã¯è¨ˆç®—ã‚³ã‚¹ãƒˆãƒ»ãƒŽã‚¤ã‚ºå¢—åŠ ã®æ‡¸å¿µã€‚

---

## âœ… 3. logical consistency ã®ä¸‹ä½è¦ç´ 

| é …ç›®                      | èª¬æ˜Ž                                                  | æ¸¬å®šæ–¹æ³•ä¾‹                                            |
| ----------------------- | --------------------------------------------------- | ------------------------------------------------ |
| relationæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯         | éš£æŽ¥ã™ã‚‹tripleé–“ã®relationãŒæ„å‘³çš„ä¸€è²«ã‹ã€‚                        | relation consistency matrixï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰ã€embeddingé¡žä¼¼åº¦ |
| concept hierarchy check | ã‚µãƒ–ã‚°ãƒ©ãƒ•å†…ã®entityé–“ã®is-aéšŽå±¤ã«ç«¶åˆãŒãªã„ã‹ï¼ˆä¾‹ï¼šæžœç‰©ã¨ä¼šç¤¾ã®æ··åœ¨ï¼‰ã€‚           | KGå†…éšŽå±¤ã€ontologyï¼ˆä¾‹ï¼šschema.orgï¼‰å‚ç…§                   |
| å› æžœãƒ»æ™‚é–“æ•´åˆæ€§                | å› æžœé–¢ä¿‚ã‚„æ™‚é–“ã®æµã‚Œã«çŸ›ç›¾ãŒãªã„ã‹ï¼ˆä¾‹ï¼šA causes Bã¨B prevents AãŒåŒæ™‚ã«ã‚ã‚‹ï¼‰ã€‚ | causal direction consistencyã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã€å…±èµ·ãƒ‘ã‚¿ãƒ¼ãƒ³        |
| semantic driftæ¤œå‡º        | è©±é¡Œã¨é–¢ä¿‚ãªã„ãƒŽãƒ¼ãƒ‰ãŒæ··å…¥ã—ã¦ã„ãªã„ã‹ï¼ˆä¾‹ï¼šSteineræœ¨ã«ä¸è¦ãƒŽãƒ¼ãƒ‰ãŒæ··å…¥ï¼‰ã€‚           | embeddingç©ºé–“ã®è·é›¢ã€å¤–ã‚Œå€¤æ¤œå‡ºã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°                     |

---

## âœ… 4. ã‚¹ã‚³ã‚¢ã®çµ±åˆæ–¹æ³•

* å„è¦ç´ ã®ã‚¹ã‚³ã‚¢ã‚’å€‹åˆ¥ã«è¨ˆç®—ã€‚
* é‡ã¿ä»˜ã‘å¹³å‡ã€å›žå¸°ãƒ¢ãƒ‡ãƒ«ã€ã¾ãŸã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹ï¼šãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã‚’ç”¨ã„ã¦çµ±åˆã€‚
* çµ±åˆå¾Œã®ç·åˆquality scoreã‚’ç”¨ã„ã¦ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»é¸æŠžã€‚

### ðŸ“ çµ±åˆã‚¹ã‚³ã‚¢ä¾‹

`Final Score = wâ‚ * logical consistency + wâ‚‚ * goal relevance + wâ‚ƒ * hop depth control`

---

## âœ… 5. å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚ºã®æµã‚Œ

1ï¸âƒ£ **ç’°å¢ƒæº–å‚™**
G-Retrieverã€Microsoft GraphRAGã€ç‹¬è‡ªé–‹ç™ºç‰ˆã®ã„ãšã‚Œã‹ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€‚

2ï¸âƒ£ **ãƒ‡ãƒ¼ã‚¿åŽé›†**
benchmarkãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã—ã€è³ªå•ã‚’å…¥åŠ›ã—ã¦ä¸­é–“ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’æŠ½å‡ºã€‚

3ï¸âƒ£ **èª¬æ˜Žå¤‰æ•°ã®è¨ˆç®—**
å„ã‚µãƒ–ã‚°ãƒ©ãƒ•ã«å¯¾ã—ã¦logical consistencyã€goal relevanceã€hop depthã€cardinalityã®å€¤ã‚’è¨ˆç®—ã€‚

4ï¸âƒ£ **ç›®çš„å¤‰æ•°ã®è¨­å®š**
ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚ã‚Šï¼ãªã—ã®LLMå‡ºåŠ›ç²¾åº¦ã®å·®åˆ†ã‚’ç›®çš„å¤‰æ•°ã¨ã™ã‚‹ï¼ˆSupervised Quality Estimationï¼‰ã€‚

5ï¸âƒ£ **å­¦ç¿’å™¨ã®æ§‹ç¯‰**
èª¬æ˜Žå¤‰æ•°ã‚’å…¥åŠ›ã€ç›®çš„å¤‰æ•°ã‚’å‡ºåŠ›ã¨ã™ã‚‹å›žå¸°ãƒ¢ãƒ‡ãƒ«ãƒ»åˆ†é¡žãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã€‚

6ï¸âƒ£ **è©•ä¾¡**
å­¦ç¿’å™¨ã®æ€§èƒ½ã‚’ç²¾åº¦ã€F1ã‚¹ã‚³ã‚¢ã€AUCãªã©ã§è©•ä¾¡ã€‚

---

## âœ… 6. chain of thoughtä»¥å¤–ã®ç›®çš„ã«ãŠã‘ã‚‹æ¡ä»¶

| ç›®çš„          | æ¡ä»¶                                     |
| ----------- | -------------------------------------- |
| äº‹å®Ÿgrounding | KGã«å«ã¾ã‚Œã‚‹ä¿¡é ¼ã§ãã‚‹äº‹å®Ÿã‚’å‚ç…§ã—ã€hallucinationã‚’æŠ‘åˆ¶ã™ã‚‹ã€‚ |
| æ§‹é€ çš„æŽ¨è«–       | ã‚¯ã‚¨ãƒªã®æ›–æ˜§ã•ãŒé«˜ã„å ´åˆã¯KGæƒ…å ±è£œå®Œã€ä½Žã„å ´åˆã¯LLMå˜ç‹¬æŽ¨è«–ã§ååˆ†ã€‚   |
| å¤–éƒ¨çŸ¥è­˜ã®å‹•çš„çµ±åˆ   | LLMãŒçŸ¥ã‚‰ãªã„æ–°è¦ãƒ»ç‰¹åŒ–çŸ¥è­˜ã‚’å¼•ãè¾¼ã‚€å ´åˆã¯é«˜ã‚¹ã‚³ã‚¢ã«ã™ã‚‹ã€‚        |

ã•ã‚‰ã«ã€LLMå´ã®chain of thoughtã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€
å˜ãªã‚‹è³ªå•æ–‡æ¯”è¼ƒã‚ˆã‚Šã‚‚æ­£ç¢ºãªçŸ¥è­˜æ¯”è¼ƒãŒå¯èƒ½ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

---

## âš™ï¸ ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆæ¦‚è¦ãƒ»æœ€æ–°æ‰‹é †ï¼‰

1. Gitç®¡ç†ï¼š

   ```bash
   git add .
   git commit -m "âœ… æœ€æ–°å¤‰æ›´: ç’°å¢ƒãƒ»ã‚³ãƒ¼ãƒ‰æ›´æ–°"
   git push origin main
   ```

2. ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–ï¼š

   ```bash
   git submodule update --init --recursive
   ```

3. Dockerãƒ“ãƒ«ãƒ‰ï¼š

   ```bash
   docker build -t graphrag-image .
   ```

4. Dockerå®Ÿè¡Œï¼š

   ```bash
   docker run -it --name graphrag-container -v ~/Projects/graphrag-research:/app graphrag-image bash
   ```

5. Condaç’°å¢ƒèµ·å‹•ï¼š

   ```bash
   conda activate graphrag_env
   ```

6. Llamaãƒ¢ãƒ‡ãƒ«æº–å‚™ï¼ˆä¾‹: meta-llama/Llama-2-7b-hfã€å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèªï¼‰ï¼š

   * HuggingFace CLIèªè¨¼ï¼ˆã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨ï¼‰
   * GPUã‚µãƒ¼ãƒãƒ¼ã§ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

7. inference.pyãƒ»train.pyã«ã‚ˆã‚‹å°è¦æ¨¡ãƒ†ã‚¹ãƒˆï¼š

   ```bash
   python inference.py
   python train.py
   ```

---

## ðŸš§ ç¾åœ¨ã®é€²è¡ŒçŠ¶æ³ï¼ˆ2025å¹´6æœˆ3æ—¥ç¾åœ¨ï¼‰

* Docker + Conda ç’°å¢ƒæ§‹ç¯‰å®Œäº†ã€‚
* GitHubã«æœ€æ–°çŠ¶æ…‹ã‚’pushæ¸ˆã¿ã€‚
* Llama 2ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å‹•ä½œç¢ºèªæº–å‚™ä¸­ï¼ˆã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—æ¸ˆã¿ï¼‰ã€‚
* inference.pyãƒ»train.pyã®ãƒ†ã‚¹ãƒˆæº–å‚™ä¸­ã€‚
* è³ªãƒ»é‡è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹ç™ºè¨ˆç”»ä¸­ã€‚

---

## ðŸ“… TODOãƒ»ä»Šå¾Œã®ä½œæ¥­äºˆå®š

* [ ] GPUã‚µãƒ¼ãƒãƒ¼ã§ã®Llama 2æŽ¨è«–ç’°å¢ƒå‹•ä½œç¢ºèªã€‚
* [ ] inference.pyã®å‡ºåŠ›ç¢ºèªãƒ»ãƒ­ã‚°æ•´å‚™ã€‚
* [ ] train.pyã«ã‚ˆã‚‹å°è¦æ¨¡å®Ÿé¨“è¨­è¨ˆã¨å®Ÿæ–½ã€‚
* [ ] è³ªãƒ»é‡ã®æŒ‡æ¨™ç®—å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆã®é–‹ç™ºã€‚
* [ ] çµ±åˆã‚¹ã‚³ã‚¢ãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆã€‚
* [ ] Gitã¨Dockerã®é€£æºå¼·åŒ–ï¼ˆã‚µãƒ¼ãƒãƒ¼å´pullãƒ»Dockerå†ãƒ“ãƒ«ãƒ‰ãªã©æ‰‹é †æ•´å‚™ï¼‰ã€‚
=======
# G-Retriever

[![arXiv](https://img.shields.io/badge/arXiv-2402.07630-b31b1b.svg)](https://arxiv.org/abs/2402.07630)

This repository contains the source code for the paper ["<u>G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering</u>"](https://arxiv.org/abs/2402.07630).

We introduce **G-Retriever**, a flexible question-answering framework targeting real-world textual graphs, applicable to multiple applications including scene graph understanding, common sense reasoning, and knowledge graph reasoning.
<img src="figs/chat.svg">

**G-Retriever** integrates the strengths of Graph Neural Networks (GNNs), Large Language Models (LLMs), and Retrieval-Augmented Generation (RAG), and can be fine-tuned to enhance graph understanding via soft prompting.
<img src="figs/overview.svg">

## News
[2024.09] [PyG 2.6](https://github.com/pyg-team/pytorch_geometric/releases/tag/2.6.0) now supports **G-Retriever**! ðŸŽ‰ \[[Dataset](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/datasets/web_qsp_dataset.html)\]\[[Model](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.GRetriever.html?highlight=gretriever)\]

## Citation
```
@inproceedings{
he2024gretriever,
title={G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering},
author={Xiaoxin He and Yijun Tian and Yifei Sun and Nitesh V Chawla and Thomas Laurent and Yann LeCun and Xavier Bresson and Bryan Hooi},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=MPJ3oXtTZl}
}
```

## Environment setup
```
conda create --name g_retriever python=3.9 -y
conda activate g_retriever

# https://pytorch.org/get-started/locally/
conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.8 -c pytorch -c nvidia

python -c "import torch; print(torch.__version__)"
python -c "import torch; print(torch.version.cuda)"
pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cu118.html

pip install peft
pip install pandas
pip install ogb
pip install transformers
pip install wandb
pip install sentencepiece
pip install torch_geometric
pip install datasets
pip install pcst_fast
pip install gensim
pip install scipy==1.12
pip install protobuf
```

## Download the Llama 2 Model
1. Go to Hugging Face: https://huggingface.co/meta-llama/Llama-2-7b-hf. You will need to share your contact information with Meta to access this model.
2. Sign up for a Hugging Face account (if you donâ€™t already have one).
3. Generate an access token: https://huggingface.co/docs/hub/en/security-tokens.
4. Add your token to the code file as follows:
  ```
  From transformers import AutoModel
  access_token = "hf_..."
  model = AutoModel.from_pretrained("private/model", token=access_token)
  ```




## Data Preprocessing
```
# expla_graphs
python -m src.dataset.preprocess.expla_graphs
python -m src.dataset.expla_graphs

# scene_graphs, might take
python -m src.dataset.preprocess.scene_graphs
python -m src.dataset.scene_graphs

# webqsp
python -m src.dataset.preprocess.webqsp
python -m src.dataset.webqsp
```

## Training
Replace path to the llm checkpoints in the `src/model/__init__.py`, then run

### 1) Inference-Only LLM
```
python inference.py --dataset scene_graphs --model_name inference_llm --llm_model_name 7b_chat
```
### 2) Frozen LLM + Prompt Tuning
```
# prompt tuning
python train.py --dataset scene_graphs_baseline --model_name pt_llm

# G-Retriever
python train.py --dataset scene_graphs --model_name graph_llm
```

### 3) Tuned LLM
```
# finetune LLM with LoRA
python train.py --dataset scene_graphs_baseline --model_name llm --llm_frozen False

# G-Retriever with LoRA
python train.py --dataset scene_graphs --model_name graph_llm --llm_frozen False
```

## Reproducibility
Use `run.sh` to run the codes and reproduce the published results in the main table.
>>>>>>> 315b0ff8a206536067602fb97e77c10f4d646d5d
